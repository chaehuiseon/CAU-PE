{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c503DSvxvOU5"
      },
      "source": [
        "# 이전 DNN 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8M2QsSUxGZn"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98Ly9UIFxIjO"
      },
      "source": [
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = raw_train_x/255.\n",
        "test_x = raw_test_x/255.\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ-hK0S5xIl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "12e3c449-62d9-4a1a-f41c-8fb0454b083c"
      },
      "source": [
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Input((28,28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0821 00:48:13.984249 140281580390272 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.7731 - acc: 0.7749\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3412 - acc: 0.9015\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2946 - acc: 0.9146\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2712 - acc: 0.9217\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2559 - acc: 0.9261\n",
            "10000/10000 [==============================] - 0s 28us/sample - loss: 0.2579 - acc: 0.9250\n",
            "loss= 0.25794000726342203\n",
            "acc= 0.925\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHcZ3XNF2qkV"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP9m1uS2fxj1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input, Reshape\n",
        "\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Hlstlof5l6",
        "outputId": "0ad74df5-eece-425e-bb75-04789c589c02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = raw_train_x/255.\n",
        "test_x = raw_test_x/255.\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRkSjvdSkgfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9429827-0067-42b7-c011-408c66c47e81"
      },
      "source": [
        "#cnn 구조\n",
        "model = keras.Sequential()\n",
        "model.add(Input((28,28))) #입력층\n",
        "#DNN에서 추가된 코드. ----------------\n",
        "#(이 부분이 없으면 DNN)\n",
        "#conv, maxpolling있는것(사용)이 CNN\n",
        "model.add(Reshape((28,28,1))) # ADDED\n",
        "\n",
        "#(3,3) : filter의 크기\n",
        "# 32 : filter의 개수 \n",
        "# (3,3)인 convolution filter적용해서 모두 32개 뽑음. padding은 입력과 출력사이즈 동일하게 same으로 맞춘다.\n",
        "model.add(Conv2D(32, (3, 3), padding='same')) # ADDED\n",
        "#maxpolling 사이즈 2x2\n",
        "model.add(MaxPooling2D((2, 2))) # ADDED\n",
        "model.add(Conv2D(64, (3, 3), padding='same')) # ADDED\n",
        "model.add(MaxPooling2D((2, 2))) # ADDED\n",
        "###-----추가된 코드 -----------------\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu')) #히든 #cf ) 여기서 히든레이어 2개인 이유는 그냥임. 교재 만들면서 무작위로 만든 것.\n",
        "model.add(Dense(10, activation='relu')) #히든\n",
        "model.add(Dense(10, activation='softmax')) #출력층\n",
        "\n",
        "#컴파일\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "#학습\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "#평가\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "#예측\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)\n",
        "#dnn으로 했을 때는 92퍼 정확도, cnn으로 했을 때는 97퍼 정확도를 보이고 있음.\n",
        "\n",
        "#conv 개수,필터 사이즈 몇개, 히든레이어 몇개, 노드 몇개, 등등 => 하이퍼 파라미터라고 함.\n",
        "# 하이퍼 파라미터를 잘 조절해야 성능이 좋아짐. -> 이 작업을 리서처가함. 이 과정을 파인튠닝이라고함. -> 실무할때는 거의 안함.\n",
        "#그럼 성능은 어케함? 연구자가 연구해놓은 결과들을 가져다가 씀.\n",
        "#imagenet competition으로 가서 우수한 성능, 모델들이 있음. ex) vgg16"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                31370     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,406\n",
            "Trainable params: 50,406\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 10s 4ms/step - loss: 0.6483 - accuracy: 0.7882\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1749 - accuracy: 0.9497\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1283 - accuracy: 0.9623\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1035 - accuracy: 0.9700\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0897 - accuracy: 0.9741\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9718\n",
            "loss= 0.09124431014060974\n",
            "acc= 0.9718000292778015\n",
            "[7 2 1 ... 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ex) vgg16\n",
        "#fileter 사이즈, 수 어케 결정? 결정 안함. 그냥 논문에 써 있는 것 가져다가 씀. 성능이 좋은 걸로\n",
        "\n",
        "model.add(Conv2D(64,(3,3),padding = \"same\"))\n",
        "model.add(Conv2D(64,(3,3),padding = \"same\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3),padding = \"same\"))\n",
        "model.add(Conv2D(128,(3,3),padding = \"same\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3),padding = \"same\"))\n",
        "model.add(Conv2D(256,(3,3),padding = \"same\"))\n",
        "model.add(Conv2D(256,(3,3),padding = \"same\"))\n",
        "model.add(Conv2D(256,(3,3),padding = \"same\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(512,(3,3),padding = \"same\"))\n",
        "model.add(Conv2D(512,(3,3),padding = \"same\"))\n",
        "model.add(Conv2D(512,(3,3),padding = \"same\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(512,(3,3),padding = \"same\"))\n",
        "model.add(Conv2D(512,(3,3),padding = \"same\"))\n",
        "model.add(Conv2D(512,(3,3),padding = \"same\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(...))\n",
        "model.add(Dense(...))\n",
        "model.add(Dense(1000,activation = \"softmax\"))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RTFJhXJLZLI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "필터의 값 같을 때 최대값을 가질 수 있음.\n",
        "\n",
        "즉, 원본 이미지에 필토 모양 성분이 얼만큼 있는지를 출력하는 것이 convolution filter의 미가됨.\n",
        "\n",
        "+) 필토 모야으이 자극이 있으면 그 결과가 최대가 된다, 필터 모양이 있는지 찾아낸다.\n",
        "\n",
        "- MaxPoolin : 최대인 값을 뽑는 것."
      ],
      "metadata": {
        "id": "4o5eprGWOhfG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky74zSK9D71P"
      },
      "source": [
        "conv2d 레이어의 파라매터 수는 다음에 의해서 결정된다.\n",
        "```\n",
        "파라매터 수 = (conv필터 가로 * conv 필터 세로 * 데이터 깊이 + bias 1개) * 필터 수\n",
        "```\n",
        "위 모델의 경우 파라매터 수 320, 18496은 다음과 같이 결정된다.\n",
        "\n",
        "```\n",
        "320 = (3*3*1+1) * 32\n",
        "\n",
        "18496 = (3*3*32+1)*64\n",
        "```\n",
        "\n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
        "_________________________________________________________________\n",
        "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2J1Y6VSf8qG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5B0uPv21ttC"
      },
      "source": [
        "# 영상 데이터 분류 CNN Template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTQwZZoR1wyT",
        "outputId": "e3919639-ffc9-4dab-d1df-64581121685f"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input, Reshape\n",
        "\n",
        "import time\n",
        "\n",
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = raw_train_x/255.\n",
        "test_x = raw_test_x/255.\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Input((28,28)))\n",
        "model.add(Reshape((28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                16010     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 35,046\n",
            "Trainable params: 35,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 56s 118ms/step - loss: 0.5551 - accuracy: 0.8262\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.1448 - accuracy: 0.9573\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 43s 91ms/step - loss: 0.0972 - accuracy: 0.9714\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 43s 92ms/step - loss: 0.0756 - accuracy: 0.9779\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 42s 89ms/step - loss: 0.0649 - accuracy: 0.9804\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0672 - accuracy: 0.9785\n",
            "loss= 0.06722691655158997\n",
            "acc= 0.9785000085830688\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eait6xD3-Hv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}